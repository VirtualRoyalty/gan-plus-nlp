{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HzI7EfYwtEUT"
   },
   "source": [
    "# Multiple-choice QA  improving via GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1683650838600,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "VAQuKzECTshu",
    "outputId": "e434e2d8-2ce6-43a6-bfd7-25dc1fe0484f"
   },
   "outputs": [],
   "source": [
    "%cd gan-plus-nlp-main/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2749,
     "status": "ok",
     "timestamp": 1683650852428,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "2PZu5XPX_990",
    "outputId": "555bff17-431c-47d4-d652-449e6dcb64ab"
   },
   "outputs": [],
   "source": [
    "# !pip install neptune-client\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib as imp\n",
    "import neptune as neptune\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# sys.path.append('gan-text-classification')\n",
    "secret = json.load(open(\"secret.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEqQ6naPBOoD"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309,
     "referenced_widgets": [
      "50f8cd6b219847d8b24f6f60ced67eb1",
      "76a885b741a94ce993130df9dc898222",
      "2c9c9824ab174f5aa54b5316582e971c",
      "5134486956da4c378135dcf2745a5667",
      "e115c69d2819440ea36c604102a5f33a",
      "51b23e6fa6964561930bb878b650661f",
      "4ca28c30c94844109458a57a7e6c53a1",
      "766279c212934acba30470a4457c1c86",
      "3f88c1bdc9e444778cca9b16abb23057",
      "4d6e56e8cba246059d2fa50bc50aab86",
      "a1f601f76549446490a900beace4b9e0"
     ]
    },
    "executionInfo": {
     "elapsed": 1985,
     "status": "ok",
     "timestamp": 1683651345012,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "8wbs17WRdxc1",
    "outputId": "b314bce4-4fc7-4cb4-a6b2-c450cfde8fda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer0', 'answer1', 'answer2', 'answer3', 'labels'],\n",
       "        num_rows: 25262\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer0', 'answer1', 'answer2', 'answer3', 'labels'],\n",
       "        num_rows: 6963\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer0', 'answer1', 'answer2', 'answer3', 'labels'],\n",
       "        num_rows: 2985\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 92;\n                var nbb_unformatted_code = \"from datasets import load_dataset, load_from_disk\\n\\ndataset_name = \\\"swag\\\"  # cosmos_qa, swag\\n# dataset = load_dataset(dataset_name, ignore_verifications=True)\\ndataset = load_from_disk(dataset_path=\\\"../data/cosmos/cosmos_qa/\\\")\\n# dataset = load_dataset(dataset_name, 'regular', ignore_verifications=True)\\ndataset = dataset.rename_column(\\\"label\\\", \\\"labels\\\")\\ndataset\";\n                var nbb_formatted_code = \"from datasets import load_dataset, load_from_disk\\n\\ndataset_name = \\\"swag\\\"  # cosmos_qa, swag\\n# dataset = load_dataset(dataset_name, ignore_verifications=True)\\ndataset = load_from_disk(dataset_path=\\\"../data/cosmos/cosmos_qa/\\\")\\n# dataset = load_dataset(dataset_name, 'regular', ignore_verifications=True)\\ndataset = dataset.rename_column(\\\"label\\\", \\\"labels\\\")\\ndataset\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "dataset_name = \"swag\"  # cosmos_qa, swag\n",
    "dataset = load_dataset(dataset_name, ignore_verifications=True)\n",
    "# dataset = load_from_disk(dataset_path=\"../data/cosmos/cosmos_qa/\")\n",
    "# dataset = load_dataset(dataset_name, 'regular', ignore_verifications=True)\n",
    "dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1683651345013,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "tiFM-SOGO0aH",
    "outputId": "40128a47-2bb0-4abe-b7e5-07246551ff71"
   },
   "outputs": [],
   "source": [
    "# _type = \"test\"\n",
    "# _indexes = np.random.permutation(len(dataset[_type]))\n",
    "# dataset[_type] = dataset[_type].select(_indexes[:6_000])\n",
    "# _type = \"validation\"\n",
    "# _indexes = np.random.permutation(len(dataset[_type]))\n",
    "# dataset[_type] = dataset[_type].select(_indexes[:3_000])\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1683651355456,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "DugQKgqjBfoy",
    "outputId": "7373bc28-476d-49c2-cef7-3ca96b88c462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0', '1', '2', '3'], 4)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 94;\n                var nbb_unformatted_code = \"# LABEL_NAMES = dataset[\\\"train\\\"].features[\\\"labels\\\"].names\\nLABEL_NAMES = dataset[\\\"train\\\"].to_pandas().labels.unique()\\n\\n# NUM_LABELS = dataset[\\\"train\\\"].features[\\\"labels\\\"].num_classes\\nNUM_LABELS = len(LABEL_NAMES)\\nLABEL_NAMES = list(map(str, range(NUM_LABELS)))\\nget_ids2label = lambda ids: [LABEL_NAMES[t] for t in ids]\\nLABEL_NAMES, NUM_LABELS\";\n                var nbb_formatted_code = \"# LABEL_NAMES = dataset[\\\"train\\\"].features[\\\"labels\\\"].names\\nLABEL_NAMES = dataset[\\\"train\\\"].to_pandas().labels.unique()\\n\\n# NUM_LABELS = dataset[\\\"train\\\"].features[\\\"labels\\\"].num_classes\\nNUM_LABELS = len(LABEL_NAMES)\\nLABEL_NAMES = list(map(str, range(NUM_LABELS)))\\nget_ids2label = lambda ids: [LABEL_NAMES[t] for t in ids]\\nLABEL_NAMES, NUM_LABELS\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LABEL_NAMES = dataset[\"train\"].features[\"labels\"].names\n",
    "LABEL_NAMES = dataset[\"train\"].to_pandas().labels.unique()\n",
    "\n",
    "# NUM_LABELS = dataset[\"train\"].features[\"labels\"].num_classes\n",
    "NUM_LABELS = len(LABEL_NAMES)\n",
    "LABEL_NAMES = list(map(str, range(NUM_LABELS)))\n",
    "get_ids2label = lambda ids: [LABEL_NAMES[t] for t in ids]\n",
    "LABEL_NAMES, NUM_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683651357409,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "u2_l3kM16-JC",
    "outputId": "0f38373f-dc33-4a88-ee83-c8c8a25a3716"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 96;\n                var nbb_unformatted_code = \"# dataset_df[\\\"context\\\"].str.split().apply(len).describe(percentiles=[0.5, 0.7, 0.9, 0.95])\\n# dataset_df[\\\"context\\\"].str.split().apply(len).describe(percentiles=[0.5, 0.7, 0.9, 0.95])\";\n                var nbb_formatted_code = \"# dataset_df[\\\"context\\\"].str.split().apply(len).describe(percentiles=[0.5, 0.7, 0.9, 0.95])\\n# dataset_df[\\\"context\\\"].str.split().apply(len).describe(percentiles=[0.5, 0.7, 0.9, 0.95])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset_df[\"context\"].str.split().apply(len).describe(percentiles=[0.5, 0.7, 0.9, 0.95])\n",
    "# dataset_df[\"context\"].str.split().apply(len).describe(percentiles=[0.5, 0.7, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683651360186,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "0IhRk7IbAWbd",
    "outputId": "eb2797a9-250b-4d00-8d62-045aa0122641"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    761\n",
       "3    751\n",
       "0    744\n",
       "1    729\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 97;\n                var nbb_unformatted_code = \"dataset_df[\\\"labels\\\"].value_counts()\";\n                var nbb_formatted_code = \"dataset_df[\\\"labels\\\"].value_counts()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZDhXt48MsR1"
   },
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683651369572,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "ZmTlIql_OUbV",
    "outputId": "a4390bd1-aaa8-4f42-d3dc-0e5ff4e014f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "3567115264\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 98;\n                var nbb_unformatted_code = \"import torch\\nimport torch.nn.functional as F\\n\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"7\\\"\\n\\nif torch.cuda.is_available():\\n    device = torch.device(\\\"cuda\\\")\\n    print(\\\"There are %d GPU(s) available.\\\" % torch.cuda.device_count())\\n    print(\\\"We will use the GPU:\\\", torch.cuda.get_device_name())\\nelse:\\n    print(\\\"No GPU available, using the CPU instead.\\\")\\n    device = torch.device(\\\"cpu\\\")\\nprint(torch.cuda.memory_allocated())\";\n                var nbb_formatted_code = \"import torch\\nimport torch.nn.functional as F\\n\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"7\\\"\\n\\nif torch.cuda.is_available():\\n    device = torch.device(\\\"cuda\\\")\\n    print(\\\"There are %d GPU(s) available.\\\" % torch.cuda.device_count())\\n    print(\\\"We will use the GPU:\\\", torch.cuda.get_device_name())\\nelse:\\n    print(\\\"No GPU available, using the CPU instead.\\\")\\n    device = torch.device(\\\"cpu\\\")\\nprint(torch.cuda.memory_allocated())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "    print(\"We will use the GPU:\", torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1624,
     "status": "ok",
     "timestamp": 1683651371606,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "gCGYLnyhOUbW",
    "outputId": "de713f34-365f-45ea-cc03-08726f776700"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 100;\n                var nbb_unformatted_code = \"import sys\\n\\ntry:\\n    del sys.modules[\\\"base\\\"]\\n    del sys.modules[\\\"model\\\"]\\n    del sys.modules[\\\"model.discriminator\\\"]\\n    del sys.modules[\\\"model.generator\\\"]\\n    del sys.modules[\\\"model.utils\\\"]\\n    # del sys.modules['model.generator']\\n    del sys.modules[\\\"trainer\\\"]\\n\\n    # del sys.modules['data_loader']\\nexcept:\\n    print(\\\"pass\\\")\\n\\ngc.collect()\\ntorch.cuda.empty_cache()\\n\\nimport model\\n\\nmodel = imp.reload(model)\";\n                var nbb_formatted_code = \"import sys\\n\\ntry:\\n    del sys.modules[\\\"base\\\"]\\n    del sys.modules[\\\"model\\\"]\\n    del sys.modules[\\\"model.discriminator\\\"]\\n    del sys.modules[\\\"model.generator\\\"]\\n    del sys.modules[\\\"model.utils\\\"]\\n    # del sys.modules['model.generator']\\n    del sys.modules[\\\"trainer\\\"]\\n\\n    # del sys.modules['data_loader']\\nexcept:\\n    print(\\\"pass\\\")\\n\\ngc.collect()\\ntorch.cuda.empty_cache()\\n\\nimport model\\n\\nmodel = imp.reload(model)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "try:\n",
    "    del sys.modules[\"base\"]\n",
    "    del sys.modules[\"model\"]\n",
    "    del sys.modules[\"model.discriminator\"]\n",
    "    del sys.modules[\"model.generator\"]\n",
    "    del sys.modules[\"model.utils\"]\n",
    "    # del sys.modules['model.generator']\n",
    "    del sys.modules[\"trainer\"]\n",
    "\n",
    "    # del sys.modules['data_loader']\n",
    "except:\n",
    "    print(\"pass\")\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import model\n",
    "\n",
    "model = imp.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RyVprDYlMoll"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"\\nmodel_name = \\\"bert-base-uncased\\\"\";\n                var nbb_formatted_code = \"model_name = \\\"bert-base-uncased\\\"\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "vLJuR2WkOqin"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 101;\n                var nbb_unformatted_code = \"CONFIG = dict(\\n    TASK=\\\"multiple-choice\\\",\\n    encoder_name=model_name,\\n    frozen_backbone=False,\\n    batch_size=8,\\n    max_seq_length=128,\\n    noise_size=100,\\n    dataset_train_size=len(dataset[\\\"train\\\"]),\\n    dataset_valid_size=len(dataset[\\\"validation\\\"]),\\n    dataset_test_size=len(dataset[\\\"test\\\"]),\\n    num_labels=NUM_LABELS,\\n    label_names=LABEL_NAMES,\\n    lr_discriminator=5e-5,\\n    lr_generator=5e-5,\\n    epsilon=1e-8,\\n    num_train_epochs=5,\\n    multi_gpu=False,\\n    dropout_rate=0.2,\\n    apply_scheduler=True,\\n    warmup_proportion_d=0.1,\\n    warmup_proportion_g=0.0,\\n    fake_label_index=-1,\\n    dataset=dataset_name,\\n    save_path=\\\"../weights/best_model.pth\\\",\\n)\";\n                var nbb_formatted_code = \"CONFIG = dict(\\n    TASK=\\\"multiple-choice\\\",\\n    encoder_name=model_name,\\n    frozen_backbone=False,\\n    batch_size=8,\\n    max_seq_length=128,\\n    noise_size=100,\\n    dataset_train_size=len(dataset[\\\"train\\\"]),\\n    dataset_valid_size=len(dataset[\\\"validation\\\"]),\\n    dataset_test_size=len(dataset[\\\"test\\\"]),\\n    num_labels=NUM_LABELS,\\n    label_names=LABEL_NAMES,\\n    lr_discriminator=5e-5,\\n    lr_generator=5e-5,\\n    epsilon=1e-8,\\n    num_train_epochs=5,\\n    multi_gpu=False,\\n    dropout_rate=0.2,\\n    apply_scheduler=True,\\n    warmup_proportion_d=0.1,\\n    warmup_proportion_g=0.0,\\n    fake_label_index=-1,\\n    dataset=dataset_name,\\n    save_path=\\\"../weights/best_model.pth\\\",\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CONFIG = dict(\n",
    "    TASK=\"multiple-choice\",\n",
    "    encoder_name=model_name,\n",
    "    frozen_backbone=False,\n",
    "    batch_size=8,\n",
    "    max_seq_length=128,\n",
    "    noise_size=100,\n",
    "    dataset_train_size=len(dataset[\"train\"]),\n",
    "    dataset_valid_size=len(dataset[\"validation\"]),\n",
    "    dataset_test_size=len(dataset[\"test\"]),\n",
    "    num_labels=NUM_LABELS,\n",
    "    label_names=LABEL_NAMES,\n",
    "    lr_discriminator=5e-5,\n",
    "    lr_generator=5e-5,\n",
    "    epsilon=1e-8,\n",
    "    num_train_epochs=5,\n",
    "    multi_gpu=False,\n",
    "    dropout_rate=0.2,\n",
    "    apply_scheduler=True,\n",
    "    warmup_proportion_d=0.1,\n",
    "    warmup_proportion_g=0.0,\n",
    "    fake_label_index=-1,\n",
    "    dataset=dataset_name,\n",
    "    save_path=\"../weights/best_model.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "tu6JrhiaLTG5"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 103;\n                var nbb_unformatted_code = \"from dataclasses import dataclass\\nimport torch\\nfrom transformers.tokenization_utils_base import (\\n    PreTrainedTokenizerBase,\\n    PaddingStrategy,\\n)\\nfrom typing import Optional, Union\\n\\n\\n# ending_names = [\\\"ending0\\\", \\\"ending1\\\", \\\"ending2\\\", \\\"ending3\\\"]\\nending_names = [\\\"answer0\\\", \\\"answer1\\\", \\\"answer2\\\", \\\"answer3\\\"]\\ncontext_name = \\\"context\\\"  # sent1 context\\nquestion_name = \\\"question\\\"  # sent2 question\\n\\n\\ndef tokenize_func(examples, num_options=4):\\n    first_sentences = [[context] * num_options for context in examples[context_name]]\\n    question_headers = examples[question_name]\\n    second_sentences = [\\n        [f\\\"{header} {examples[end][i]}\\\" for end in ending_names]\\n        for i, header in enumerate(question_headers)\\n    ]\\n\\n    first_sentences = sum(first_sentences, [])\\n    second_sentences = sum(second_sentences, [])\\n\\n    tokenized_examples = tokenizer(\\n        first_sentences,\\n        second_sentences,\\n        truncation=True,\\n        max_length=CONFIG[\\\"max_seq_length\\\"],\\n    )\\n    return {\\n        k: [v[i : i + num_options] for i in range(0, len(v), num_options)]\\n        for k, v in tokenized_examples.items()\\n    }\\n\\n\\n@dataclass\\nclass DataCollatorForMultipleChoice:\\n    \\\"\\\"\\\"\\n    Data collator that will dynamically pad the inputs for multiple choice received.\\n    \\\"\\\"\\\"\\n\\n    tokenizer: PreTrainedTokenizerBase\\n    padding: Union[bool, str, PaddingStrategy] = True\\n    max_length: Optional[int] = None\\n    pad_to_multiple_of: Optional[int] = None\\n\\n    def __call__(self, features):\\n        label_name = \\\"label\\\" if \\\"label\\\" in features[0].keys() else \\\"labels\\\"\\n        labels = [feature.pop(label_name) for feature in features]\\n        try:\\n            labeled_mask = [feature.pop(\\\"labeled_mask\\\") for feature in features]\\n        except:\\n            labeled_mask = [True] * len(features)\\n        batch_size = len(features)\\n        num_choices = len(features[0][\\\"input_ids\\\"])\\n        flattened_features = [\\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)]\\n            for feature in features\\n        ]\\n        flattened_features = sum(flattened_features, [])\\n\\n        batch = self.tokenizer.pad(\\n            flattened_features,\\n            padding=self.padding,\\n            max_length=self.max_length,\\n            pad_to_multiple_of=self.pad_to_multiple_of,\\n            return_tensors=\\\"pt\\\",\\n        )\\n\\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\\n        batch[\\\"labels\\\"] = torch.tensor(labels, dtype=torch.int64)\\n        batch[\\\"labeled_mask\\\"] = torch.tensor(labeled_mask, dtype=torch.bool)\\n        return batch\";\n                var nbb_formatted_code = \"from dataclasses import dataclass\\nimport torch\\nfrom transformers.tokenization_utils_base import (\\n    PreTrainedTokenizerBase,\\n    PaddingStrategy,\\n)\\nfrom typing import Optional, Union\\n\\n\\n# ending_names = [\\\"ending0\\\", \\\"ending1\\\", \\\"ending2\\\", \\\"ending3\\\"]\\nending_names = [\\\"answer0\\\", \\\"answer1\\\", \\\"answer2\\\", \\\"answer3\\\"]\\ncontext_name = \\\"context\\\"  # sent1 context\\nquestion_name = \\\"question\\\"  # sent2 question\\n\\n\\ndef tokenize_func(examples, num_options=4):\\n    first_sentences = [[context] * num_options for context in examples[context_name]]\\n    question_headers = examples[question_name]\\n    second_sentences = [\\n        [f\\\"{header} {examples[end][i]}\\\" for end in ending_names]\\n        for i, header in enumerate(question_headers)\\n    ]\\n\\n    first_sentences = sum(first_sentences, [])\\n    second_sentences = sum(second_sentences, [])\\n\\n    tokenized_examples = tokenizer(\\n        first_sentences,\\n        second_sentences,\\n        truncation=True,\\n        max_length=CONFIG[\\\"max_seq_length\\\"],\\n    )\\n    return {\\n        k: [v[i : i + num_options] for i in range(0, len(v), num_options)]\\n        for k, v in tokenized_examples.items()\\n    }\\n\\n\\n@dataclass\\nclass DataCollatorForMultipleChoice:\\n    \\\"\\\"\\\"\\n    Data collator that will dynamically pad the inputs for multiple choice received.\\n    \\\"\\\"\\\"\\n\\n    tokenizer: PreTrainedTokenizerBase\\n    padding: Union[bool, str, PaddingStrategy] = True\\n    max_length: Optional[int] = None\\n    pad_to_multiple_of: Optional[int] = None\\n\\n    def __call__(self, features):\\n        label_name = \\\"label\\\" if \\\"label\\\" in features[0].keys() else \\\"labels\\\"\\n        labels = [feature.pop(label_name) for feature in features]\\n        try:\\n            labeled_mask = [feature.pop(\\\"labeled_mask\\\") for feature in features]\\n        except:\\n            labeled_mask = [True] * len(features)\\n        batch_size = len(features)\\n        num_choices = len(features[0][\\\"input_ids\\\"])\\n        flattened_features = [\\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)]\\n            for feature in features\\n        ]\\n        flattened_features = sum(flattened_features, [])\\n\\n        batch = self.tokenizer.pad(\\n            flattened_features,\\n            padding=self.padding,\\n            max_length=self.max_length,\\n            pad_to_multiple_of=self.pad_to_multiple_of,\\n            return_tensors=\\\"pt\\\",\\n        )\\n\\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\\n        batch[\\\"labels\\\"] = torch.tensor(labels, dtype=torch.int64)\\n        batch[\\\"labeled_mask\\\"] = torch.tensor(labeled_mask, dtype=torch.bool)\\n        return batch\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from transformers.tokenization_utils_base import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PaddingStrategy,\n",
    ")\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
    "ending_names = [\"answer0\", \"answer1\", \"answer2\", \"answer3\"]\n",
    "context_name = \"context\"  # sent1 context\n",
    "question_name = \"question\"  # sent2 question\n",
    "\n",
    "\n",
    "def tokenize_func(examples, num_options=4):\n",
    "    first_sentences = [[context] * num_options for context in examples[context_name]]\n",
    "    question_headers = examples[question_name]\n",
    "    second_sentences = [\n",
    "        [f\"{header} {examples[end][i]}\" for end in ending_names]\n",
    "        for i, header in enumerate(question_headers)\n",
    "    ]\n",
    "\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    tokenized_examples = tokenizer(\n",
    "        first_sentences,\n",
    "        second_sentences,\n",
    "        truncation=True,\n",
    "        max_length=CONFIG[\"max_seq_length\"],\n",
    "    )\n",
    "    return {\n",
    "        k: [v[i : i + num_options] for i in range(0, len(v), num_options)]\n",
    "        for k, v in tokenized_examples.items()\n",
    "    }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        try:\n",
    "            labeled_mask = [feature.pop(\"labeled_mask\") for feature in features]\n",
    "        except:\n",
    "            labeled_mask = [True] * len(features)\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)]\n",
    "            for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        batch[\"labeled_mask\"] = torch.tensor(labeled_mask, dtype=torch.bool)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1683653349346,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "YpHbMIHho76O",
    "outputId": "82bdd634-5ac1-450f-f70f-5b4fbdd54ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplier: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/valperovich/projects/other/std/data/cosmos/cosmos_qa/validation/cache-9997cab0262ad41f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN (FOR only discriminator): 40\n",
      "TRAIN (FOR GAN): 1160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'labeled_mask'],\n",
       "        num_rows: 1160\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2985\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2985\n",
       "    })\n",
       "    train_only_labeled: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'labeled_mask'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 104;\n                var nbb_unformatted_code = \"from copy import copy\\nfrom datasets import Dataset\\nfrom transformers import DataCollatorWithPadding\\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\\n\\nLABELED_SIZE = 40\\nUNLABELED_SIZE = 1000\\nFULL_SIZE = LABELED_SIZE + UNLABELED_SIZE\\nmultiplier = int(np.log2(FULL_SIZE / LABELED_SIZE))\\nmultiplier = max(1, multiplier)\\nprint(\\\"Multiplier:\\\", multiplier)\\n\\nnp.random.seed(42)\\n\\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\\n\\n\\ndef prepare_experiment_datasets(LABELED_SIZE, UNLABELED_SIZE, FULL_SIZE, multiplier):\\n    tokenized_dataset = dataset.map(tokenize_func, batched=True)\\n    try:\\n        tokenized_dataset = tokenized_dataset.select_columns(\\n            [\\\"labels\\\", \\\"input_ids\\\", \\\"token_type_ids\\\", \\\"attention_mask\\\"]\\n        )\\n    except:\\n        tokenized_dataset = tokenized_dataset.select_columns(\\n            [\\\"labels\\\", \\\"input_ids\\\", \\\"attention_mask\\\"]\\n        )\\n    tokenized_train_df = tokenized_dataset[\\\"train\\\"].to_pandas()\\n    tokenized_train_df_labeled = tokenized_train_df.sample(LABELED_SIZE)\\n    tokenized_train_df_labeled[\\\"labeled_mask\\\"] = True\\n\\n    tokenized_train_df = tokenized_train_df.sample(UNLABELED_SIZE)\\n    tokenized_train_df[\\\"labeled_mask\\\"] = False\\n    tokenized_train_df[\\\"labels\\\"] = -100\\n\\n    for _ in range(multiplier):\\n        tokenized_train_df = tokenized_train_df.append(tokenized_train_df_labeled)\\n\\n    tokenized_dataset[\\\"train\\\"] = Dataset.from_pandas(\\n        tokenized_train_df, preserve_index=False\\n    )\\n    tokenized_dataset[\\\"train_only_labeled\\\"] = Dataset.from_pandas(\\n        tokenized_train_df_labeled, preserve_index=False\\n    )\\n    print(\\n        \\\"TRAIN (FOR only discriminator):\\\", len(tokenized_dataset[\\\"train_only_labeled\\\"])\\n    )\\n    print(\\\"TRAIN (FOR GAN):\\\", len(tokenized_dataset[\\\"train\\\"]))\\n    # tokenized_train_df.labels.value_counts()\\n    return tokenized_dataset\\n\\n\\ntokenized_dataset = prepare_experiment_datasets(\\n    LABELED_SIZE, UNLABELED_SIZE, FULL_SIZE, multiplier\\n)\\ntokenized_dataset\";\n                var nbb_formatted_code = \"from copy import copy\\nfrom datasets import Dataset\\nfrom transformers import DataCollatorWithPadding\\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\\n\\nLABELED_SIZE = 40\\nUNLABELED_SIZE = 1000\\nFULL_SIZE = LABELED_SIZE + UNLABELED_SIZE\\nmultiplier = int(np.log2(FULL_SIZE / LABELED_SIZE))\\nmultiplier = max(1, multiplier)\\nprint(\\\"Multiplier:\\\", multiplier)\\n\\nnp.random.seed(42)\\n\\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\\n\\n\\ndef prepare_experiment_datasets(LABELED_SIZE, UNLABELED_SIZE, FULL_SIZE, multiplier):\\n    tokenized_dataset = dataset.map(tokenize_func, batched=True)\\n    try:\\n        tokenized_dataset = tokenized_dataset.select_columns(\\n            [\\\"labels\\\", \\\"input_ids\\\", \\\"token_type_ids\\\", \\\"attention_mask\\\"]\\n        )\\n    except:\\n        tokenized_dataset = tokenized_dataset.select_columns(\\n            [\\\"labels\\\", \\\"input_ids\\\", \\\"attention_mask\\\"]\\n        )\\n    tokenized_train_df = tokenized_dataset[\\\"train\\\"].to_pandas()\\n    tokenized_train_df_labeled = tokenized_train_df.sample(LABELED_SIZE)\\n    tokenized_train_df_labeled[\\\"labeled_mask\\\"] = True\\n\\n    tokenized_train_df = tokenized_train_df.sample(UNLABELED_SIZE)\\n    tokenized_train_df[\\\"labeled_mask\\\"] = False\\n    tokenized_train_df[\\\"labels\\\"] = -100\\n\\n    for _ in range(multiplier):\\n        tokenized_train_df = tokenized_train_df.append(tokenized_train_df_labeled)\\n\\n    tokenized_dataset[\\\"train\\\"] = Dataset.from_pandas(\\n        tokenized_train_df, preserve_index=False\\n    )\\n    tokenized_dataset[\\\"train_only_labeled\\\"] = Dataset.from_pandas(\\n        tokenized_train_df_labeled, preserve_index=False\\n    )\\n    print(\\n        \\\"TRAIN (FOR only discriminator):\\\", len(tokenized_dataset[\\\"train_only_labeled\\\"])\\n    )\\n    print(\\\"TRAIN (FOR GAN):\\\", len(tokenized_dataset[\\\"train\\\"]))\\n    # tokenized_train_df.labels.value_counts()\\n    return tokenized_dataset\\n\\n\\ntokenized_dataset = prepare_experiment_datasets(\\n    LABELED_SIZE, UNLABELED_SIZE, FULL_SIZE, multiplier\\n)\\ntokenized_dataset\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import copy\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "LABELED_SIZE = 40\n",
    "UNLABELED_SIZE = 1000\n",
    "FULL_SIZE = LABELED_SIZE + UNLABELED_SIZE\n",
    "multiplier = int(np.log2(FULL_SIZE / LABELED_SIZE))\n",
    "multiplier = max(1, multiplier)\n",
    "print(\"Multiplier:\", multiplier)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def prepare_experiment_datasets(LABELED_SIZE, UNLABELED_SIZE, FULL_SIZE, multiplier):\n",
    "    tokenized_dataset = dataset.map(tokenize_func, batched=True)\n",
    "    try:\n",
    "        tokenized_dataset = tokenized_dataset.select_columns(\n",
    "            [\"labels\", \"input_ids\", \"token_type_ids\", \"attention_mask\"]\n",
    "        )\n",
    "    except:\n",
    "        tokenized_dataset = tokenized_dataset.select_columns(\n",
    "            [\"labels\", \"input_ids\", \"attention_mask\"]\n",
    "        )\n",
    "    tokenized_train_df = tokenized_dataset[\"train\"].to_pandas()\n",
    "    tokenized_train_df_labeled = tokenized_train_df.sample(LABELED_SIZE)\n",
    "    tokenized_train_df_labeled[\"labeled_mask\"] = True\n",
    "\n",
    "    tokenized_train_df = tokenized_train_df.sample(UNLABELED_SIZE)\n",
    "    tokenized_train_df[\"labeled_mask\"] = False\n",
    "    tokenized_train_df[\"labels\"] = -100\n",
    "\n",
    "    for _ in range(multiplier):\n",
    "        tokenized_train_df = tokenized_train_df.append(tokenized_train_df_labeled)\n",
    "\n",
    "    tokenized_dataset[\"train\"] = Dataset.from_pandas(\n",
    "        tokenized_train_df, preserve_index=False\n",
    "    )\n",
    "    tokenized_dataset[\"train_only_labeled\"] = Dataset.from_pandas(\n",
    "        tokenized_train_df_labeled, preserve_index=False\n",
    "    )\n",
    "    print(\n",
    "        \"TRAIN (FOR only discriminator):\", len(tokenized_dataset[\"train_only_labeled\"])\n",
    "    )\n",
    "    print(\"TRAIN (FOR GAN):\", len(tokenized_dataset[\"train\"]))\n",
    "    # tokenized_train_df.labels.value_counts()\n",
    "    return tokenized_dataset\n",
    "\n",
    "\n",
    "tokenized_dataset = prepare_experiment_datasets(\n",
    "    LABELED_SIZE, UNLABELED_SIZE, FULL_SIZE, multiplier\n",
    ")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "GoXIv64GLvnv"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 100;\n                var nbb_unformatted_code = \"train_only_labeled_dataloader = DataLoader(\\n    tokenized_dataset[\\\"train_only_labeled\\\"],\\n    batch_size=CONFIG[\\\"batch_size\\\"],\\n    sampler=RandomSampler(tokenized_dataset[\\\"train_only_labeled\\\"]),\\n    collate_fn=data_collator,\\n    pin_memory=True,\\n)\\n\\ntrain_dataloader = DataLoader(\\n    tokenized_dataset[\\\"train\\\"],\\n    batch_size=CONFIG[\\\"batch_size\\\"],\\n    sampler=RandomSampler(tokenized_dataset[\\\"train\\\"]),\\n    collate_fn=data_collator,\\n    pin_memory=True,\\n)\\n\\nvalid_dataloader = DataLoader(\\n    tokenized_dataset[\\\"validation\\\"],\\n    batch_size=CONFIG[\\\"batch_size\\\"],\\n    sampler=SequentialSampler(tokenized_dataset[\\\"validation\\\"]),\\n    collate_fn=data_collator,\\n    pin_memory=True,\\n)\\n\\ntest_dataloader = DataLoader(\\n    tokenized_dataset[\\\"test\\\"],\\n    batch_size=16,\\n    sampler=SequentialSampler(tokenized_dataset[\\\"test\\\"]),\\n    collate_fn=data_collator,\\n    pin_memory=True,\\n)\";\n                var nbb_formatted_code = \"train_only_labeled_dataloader = DataLoader(\\n    tokenized_dataset[\\\"train_only_labeled\\\"],\\n    batch_size=CONFIG[\\\"batch_size\\\"],\\n    sampler=RandomSampler(tokenized_dataset[\\\"train_only_labeled\\\"]),\\n    collate_fn=data_collator,\\n    pin_memory=True,\\n)\\n\\ntrain_dataloader = DataLoader(\\n    tokenized_dataset[\\\"train\\\"],\\n    batch_size=CONFIG[\\\"batch_size\\\"],\\n    sampler=RandomSampler(tokenized_dataset[\\\"train\\\"]),\\n    collate_fn=data_collator,\\n    pin_memory=True,\\n)\\n\\nvalid_dataloader = DataLoader(\\n    tokenized_dataset[\\\"validation\\\"],\\n    batch_size=CONFIG[\\\"batch_size\\\"],\\n    sampler=SequentialSampler(tokenized_dataset[\\\"validation\\\"]),\\n    collate_fn=data_collator,\\n    pin_memory=True,\\n)\\n\\ntest_dataloader = DataLoader(\\n    tokenized_dataset[\\\"test\\\"],\\n    batch_size=16,\\n    sampler=SequentialSampler(tokenized_dataset[\\\"test\\\"]),\\n    collate_fn=data_collator,\\n    pin_memory=True,\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_only_labeled_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"train_only_labeled\"],\n",
    "    batch_size=CONFIG[\"batch_size\"],\n",
    "    sampler=RandomSampler(tokenized_dataset[\"train_only_labeled\"]),\n",
    "    collate_fn=data_collator,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=CONFIG[\"batch_size\"],\n",
    "    sampler=RandomSampler(tokenized_dataset[\"train\"]),\n",
    "    collate_fn=data_collator,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"validation\"],\n",
    "    batch_size=CONFIG[\"batch_size\"],\n",
    "    sampler=SequentialSampler(tokenized_dataset[\"validation\"]),\n",
    "    collate_fn=data_collator,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"test\"],\n",
    "    batch_size=16,\n",
    "    sampler=SequentialSampler(tokenized_dataset[\"test\"]),\n",
    "    collate_fn=data_collator,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZgyRUTEhuV3"
   },
   "source": [
    "### Train only discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2684,
     "status": "ok",
     "timestamp": 1683653362482,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "eJWOTL7QtqsL",
    "outputId": "4594abba-409f-48fa-b5b1-cc642232d827"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 101;\n                var nbb_unformatted_code = \"import gc\\n\\n# del discriminator\\ntorch.cuda.empty_cache()\\ngc.collect()\";\n                var nbb_formatted_code = \"import gc\\n\\n# del discriminator\\ntorch.cuda.empty_cache()\\ngc.collect()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# del discriminator\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "ysG51ZoYAoLq"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 102;\n                var nbb_unformatted_code = \"from trainer import trainer as trainer_module\\nfrom trainer import gan_trainer as gan_trainer_module\\n\\ntrainer_module = imp.reload(trainer_module)\\ngan_trainer_module = imp.reload(gan_trainer_module)\";\n                var nbb_formatted_code = \"from trainer import trainer as trainer_module\\nfrom trainer import gan_trainer as gan_trainer_module\\n\\ntrainer_module = imp.reload(trainer_module)\\ngan_trainer_module = imp.reload(gan_trainer_module)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trainer import trainer as trainer_module\n",
    "from trainer import gan_trainer as gan_trainer_module\n",
    "\n",
    "trainer_module = imp.reload(trainer_module)\n",
    "gan_trainer_module = imp.reload(gan_trainer_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "VWrPGdzscVMx"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 103;\n                var nbb_unformatted_code = \"from copy import copy\\n\\nBASE_CONFIG = copy(CONFIG)\\nBASE_CONFIG[\\\"GAN\\\"] = False\\nBASE_CONFIG[\\\"gan_training\\\"] = False\\nBASE_CONFIG[\\\"num_labels\\\"] = NUM_LABELS\\nBASE_CONFIG[\\\"LABELED_SIZE\\\"] = LABELED_SIZE\\nBASE_CONFIG[\\\"num_train_epochs\\\"] = 3\\n# BASE_CONFIG\";\n                var nbb_formatted_code = \"from copy import copy\\n\\nBASE_CONFIG = copy(CONFIG)\\nBASE_CONFIG[\\\"GAN\\\"] = False\\nBASE_CONFIG[\\\"gan_training\\\"] = False\\nBASE_CONFIG[\\\"num_labels\\\"] = NUM_LABELS\\nBASE_CONFIG[\\\"LABELED_SIZE\\\"] = LABELED_SIZE\\nBASE_CONFIG[\\\"num_train_epochs\\\"] = 3\\n# BASE_CONFIG\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "BASE_CONFIG = copy(CONFIG)\n",
    "BASE_CONFIG[\"GAN\"] = False\n",
    "BASE_CONFIG[\"gan_training\"] = False\n",
    "BASE_CONFIG[\"num_labels\"] = NUM_LABELS\n",
    "BASE_CONFIG[\"LABELED_SIZE\"] = LABELED_SIZE\n",
    "BASE_CONFIG[\"num_train_epochs\"] = 3\n",
    "# BASE_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1683653363067,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "eWb2B89OHDU3",
    "outputId": "5a60ce44-9282-4ff9-eeab-af195b9f5533"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"# discriminator = model.DiscriminatorForMultipleChoice(**BASE_CONFIG)\";\n                var nbb_formatted_code = \"# discriminator = model.DiscriminatorForMultipleChoice(**BASE_CONFIG)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discriminator = model.DiscriminatorForMultipleChoice(**BASE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1683653363067,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "mevAQ5KlGdlt",
    "outputId": "e35121ca-7a93-45ca-e091-8959bd6d83db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers 201\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 105;\n                var nbb_unformatted_code = \"from trainer import trainer\\n\\ntrainer = imp.reload(trainer)\\n\\nBASE_CONFIG[\\\"num_train_examples\\\"] = len(train_only_labeled_dataloader.dataset)\\ntrainer = trainer.TrainerSequenceClassification(\\n    config=BASE_CONFIG,\\n    discriminator=discriminator,\\n    train_dataloader=train_only_labeled_dataloader,\\n    valid_dataloader=valid_dataloader,\\n    device=device,\\n)\";\n                var nbb_formatted_code = \"from trainer import trainer\\n\\ntrainer = imp.reload(trainer)\\n\\nBASE_CONFIG[\\\"num_train_examples\\\"] = len(train_only_labeled_dataloader.dataset)\\ntrainer = trainer.TrainerSequenceClassification(\\n    config=BASE_CONFIG,\\n    discriminator=discriminator,\\n    train_dataloader=train_only_labeled_dataloader,\\n    valid_dataloader=valid_dataloader,\\n    device=device,\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trainer import trainer\n",
    "\n",
    "trainer = imp.reload(trainer)\n",
    "\n",
    "BASE_CONFIG[\"num_train_examples\"] = len(train_only_labeled_dataloader.dataset)\n",
    "trainer = trainer.TrainerSequenceClassification(\n",
    "    config=BASE_CONFIG,\n",
    "    discriminator=discriminator,\n",
    "    train_dataloader=train_only_labeled_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    device=device,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342146,
     "status": "ok",
     "timestamp": 1683653705210,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "feZb9dx3GdbS",
    "outputId": "25101309-b0a2-4198-e054-cf8443b14a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/vmalperovich/gan-in-nlp/e/GAN2-321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 3 ========\n",
      "\tTrain loss discriminator: 1.439\n",
      "\tTest loss discriminator: 1.383\n",
      "\tTest accuracy discriminator: 0.304\n",
      "\tTest f1 discriminator: 0.304\n",
      "======== Epoch 2 / 3 ========\n",
      "\tTrain loss discriminator: 1.383\n",
      "\tTest loss discriminator: 1.352\n",
      "\tTest accuracy discriminator: 0.280\n",
      "\tTest f1 discriminator: 0.280\n",
      "======== Epoch 3 / 3 ========\n",
      "\tTrain loss discriminator: 1.298\n",
      "\tTest loss discriminator: 1.330\n",
      "\tTest accuracy discriminator: 0.397\n",
      "\tTest f1 discriminator: 0.397\n",
      "CPU times: user 1min 50s, sys: 602 ms, total: 1min 51s\n",
      "Wall time: 1min 51s\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 106;\n                var nbb_unformatted_code = \"%%time\\nrun = None\\ntags = ['test']\\nrun = neptune.init_run(\\n    project=secret[\\\"neptune_project\\\"], api_token=secret[\\\"neptune_token\\\"], tags=tags\\n)\\nrun[\\\"config\\\"] = trainer.config\\n\\nfor epoch_i in range(BASE_CONFIG[\\\"num_train_epochs\\\"]):\\n    print(f\\\"======== Epoch {epoch_i + 1} / {BASE_CONFIG['num_train_epochs']} ========\\\")\\n    train_info = trainer.train_epoch(log_env=run)\\n    valid_metrics = trainer.validation(log_env=run)\\n# run.stop()\";\n                var nbb_formatted_code = \"%%time\\nrun = None\\ntags = ['test']\\nrun = neptune.init_run(\\n    project=secret[\\\"neptune_project\\\"], api_token=secret[\\\"neptune_token\\\"], tags=tags\\n)\\nrun[\\\"config\\\"] = trainer.config\\n\\nfor epoch_i in range(BASE_CONFIG[\\\"num_train_epochs\\\"]):\\n    print(f\\\"======== Epoch {epoch_i + 1} / {BASE_CONFIG['num_train_epochs']} ========\\\")\\n    train_info = trainer.train_epoch(log_env=run)\\n    valid_metrics = trainer.validation(log_env=run)\\n# run.stop()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "run = None\n",
    "tags = ['test']\n",
    "run = neptune.init_run(\n",
    "    project=secret[\"neptune_project\"], api_token=secret[\"neptune_token\"], tags=tags\n",
    ")\n",
    "run[\"config\"] = trainer.config\n",
    "\n",
    "for epoch_i in range(BASE_CONFIG[\"num_train_epochs\"]):\n",
    "    print(f\"======== Epoch {epoch_i + 1} / {BASE_CONFIG['num_train_epochs']} ========\")\n",
    "    train_info = trainer.train_epoch(log_env=run)\n",
    "    valid_metrics = trainer.validation(log_env=run)\n",
    "# run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112313,
     "status": "ok",
     "timestamp": 1683653817518,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "OCf7QL-9duh7",
    "outputId": "c6148b0e-561b-448c-baf5-278e49dbb053"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# %%time\\n# predict_info = trainer.predict(\\n#     discriminator, test_dataloader, label_names=CONFIG[\\\"label_names\\\"]\\n# )\\n# run[\\\"test\\\"] = predict_info\\n# run.stop()\\n# predict_info\";\n                var nbb_formatted_code = \"# %%time\\n# predict_info = trainer.predict(\\n#     discriminator, test_dataloader, label_names=CONFIG[\\\"label_names\\\"]\\n# )\\n# run[\\\"test\\\"] = predict_info\\n# run.stop()\\n# predict_info\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "predict_info = trainer.predict(\n",
    "    discriminator, test_dataloader, label_names=CONFIG[\"label_names\"]\n",
    ")\n",
    "run[\"test\"] = predict_info\n",
    "run.stop()\n",
    "predict_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Emltuf91h0KL"
   },
   "source": [
    "### Train via GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1683653817976,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "JdrzbtnJIVox",
    "outputId": "ca094e69-600e-4ee9-ae5b-3f3df6c16f0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 108;\n                var nbb_unformatted_code = \"import gc\\n\\ntorch.cuda.empty_cache()\\ngc.collect()\";\n                var nbb_formatted_code = \"import gc\\n\\ntorch.cuda.empty_cache()\\ngc.collect()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "8NY8tCLlgaNz"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 109;\n                var nbb_unformatted_code = \"from copy import copy\\n\\nGAN_CONFIG = copy(CONFIG)\\nGAN_CONFIG[\\\"GAN\\\"] = True\\nGAN_CONFIG[\\\"gan_training\\\"] = True\\nGAN_CONFIG[\\\"GAN_TYPE\\\"] = \\\"dummy\\\"  # \\\"attention\\\" \\\"mixed\\\" \\\"dummy\\\"\\nGAN_CONFIG[\\\"mixed_fake_ratio\\\"] = 0.2\\nGAN_CONFIG[\\\"LABELED_SIZE\\\"] = LABELED_SIZE\\nGAN_CONFIG[\\\"UNLABELED_SIZE\\\"] = UNLABELED_SIZE\\nGAN_CONFIG[\\\"noise_type\\\"] = \\\"normal\\\"\\nGAN_CONFIG[\\\"noise_range\\\"] = (0, 1)\\nGAN_CONFIG[\\\"warmup_proportion_d\\\"] = 0.05\\nGAN_CONFIG[\\\"gen_multiplier\\\"] = 4\\nGAN_CONFIG[\\\"num_train_epochs\\\"] = 3\\n# GAN_CONFIG\";\n                var nbb_formatted_code = \"from copy import copy\\n\\nGAN_CONFIG = copy(CONFIG)\\nGAN_CONFIG[\\\"GAN\\\"] = True\\nGAN_CONFIG[\\\"gan_training\\\"] = True\\nGAN_CONFIG[\\\"GAN_TYPE\\\"] = \\\"dummy\\\"  # \\\"attention\\\" \\\"mixed\\\" \\\"dummy\\\"\\nGAN_CONFIG[\\\"mixed_fake_ratio\\\"] = 0.2\\nGAN_CONFIG[\\\"LABELED_SIZE\\\"] = LABELED_SIZE\\nGAN_CONFIG[\\\"UNLABELED_SIZE\\\"] = UNLABELED_SIZE\\nGAN_CONFIG[\\\"noise_type\\\"] = \\\"normal\\\"\\nGAN_CONFIG[\\\"noise_range\\\"] = (0, 1)\\nGAN_CONFIG[\\\"warmup_proportion_d\\\"] = 0.05\\nGAN_CONFIG[\\\"gen_multiplier\\\"] = 4\\nGAN_CONFIG[\\\"num_train_epochs\\\"] = 3\\n# GAN_CONFIG\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "GAN_CONFIG = copy(CONFIG)\n",
    "GAN_CONFIG[\"GAN\"] = True\n",
    "GAN_CONFIG[\"gan_training\"] = True\n",
    "GAN_CONFIG[\"GAN_TYPE\"] = \"dummy\" \n",
    "GAN_CONFIG[\"mixed_fake_ratio\"] = 0.2\n",
    "GAN_CONFIG[\"LABELED_SIZE\"] = LABELED_SIZE\n",
    "GAN_CONFIG[\"UNLABELED_SIZE\"] = UNLABELED_SIZE\n",
    "GAN_CONFIG[\"noise_type\"] = \"normal\"\n",
    "GAN_CONFIG[\"noise_range\"] = (0, 1)\n",
    "GAN_CONFIG[\"warmup_proportion_d\"] = 0.05\n",
    "GAN_CONFIG[\"gen_multiplier\"] = 4\n",
    "GAN_CONFIG[\"num_train_epochs\"] = 3\n",
    "# GAN_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1730,
     "status": "ok",
     "timestamp": 1683653819704,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "KBiAZxTY6dh7",
    "outputId": "0a15fbf6-2609-4524-96cb-ad961d825d6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with GAN mode on!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleSequenceGenerator(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=768, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Dropout(p=0.2, inplace=False)\n",
       "    (7): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 110;\n                var nbb_unformatted_code = \"if GAN_CONFIG[\\\"GAN_TYPE\\\"] == \\\"dummy\\\":\\n    generator = model.SimpleSequenceGenerator(\\n        input_size=CONFIG[\\\"noise_size\\\"],\\n        output_size=discriminator.encoder.config.hidden_size,\\n    )\\nelif GAN_CONFIG[\\\"GAN_TYPE\\\"] == \\\"attention\\\":\\n    generator = model.ContextualGenerator(\\n        input_size=GAN_CONFIG[\\\"noise_size\\\"],\\n        output_size=discriminator.encoder.config.hidden_size,\\n    )\\nelse:\\n    raise \\\"ERROR\\\"\\ndiscriminator = model.DiscriminatorForMultipleChoice(**GAN_CONFIG)\\ngenerator\";\n                var nbb_formatted_code = \"if GAN_CONFIG[\\\"GAN_TYPE\\\"] == \\\"dummy\\\":\\n    generator = model.SimpleSequenceGenerator(\\n        input_size=CONFIG[\\\"noise_size\\\"],\\n        output_size=discriminator.encoder.config.hidden_size,\\n    )\\nelif GAN_CONFIG[\\\"GAN_TYPE\\\"] == \\\"attention\\\":\\n    generator = model.ContextualGenerator(\\n        input_size=GAN_CONFIG[\\\"noise_size\\\"],\\n        output_size=discriminator.encoder.config.hidden_size,\\n    )\\nelse:\\n    raise \\\"ERROR\\\"\\ndiscriminator = model.DiscriminatorForMultipleChoice(**GAN_CONFIG)\\ngenerator\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = model.SimpleSequenceGenerator(\n",
    "    input_size=CONFIG[\"noise_size\"],\n",
    "    output_size=discriminator.encoder.config.hidden_size,\n",
    ")\n",
    "\n",
    "discriminator = model.DiscriminatorForMultipleChoice(**GAN_CONFIG)\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1683653819705,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "42peLTZI6ddc",
    "outputId": "35e80e2d-289f-476d-e168-e9982f0efee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers 201\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 111;\n                var nbb_unformatted_code = \"from trainer import gan_trainer as gan_trainer_module\\n\\ngan_trainer_module = imp.reload(gan_trainer_module)\\n\\nGAN_CONFIG[\\\"num_train_examples\\\"] = len(train_dataloader.dataset)\\ngan_trainer = gan_trainer_module.GANTrainerMultipleChoice(\\n    config=GAN_CONFIG,\\n    discriminator=discriminator,\\n    generator=generator,\\n    train_dataloader=train_dataloader,\\n    valid_dataloader=valid_dataloader,\\n    device=device,\\n    save_path=CONFIG['save_path']\\n)\";\n                var nbb_formatted_code = \"from trainer import gan_trainer as gan_trainer_module\\n\\ngan_trainer_module = imp.reload(gan_trainer_module)\\n\\nGAN_CONFIG[\\\"num_train_examples\\\"] = len(train_dataloader.dataset)\\ngan_trainer = gan_trainer_module.GANTrainerMultipleChoice(\\n    config=GAN_CONFIG,\\n    discriminator=discriminator,\\n    generator=generator,\\n    train_dataloader=train_dataloader,\\n    valid_dataloader=valid_dataloader,\\n    device=device,\\n    save_path=CONFIG[\\\"save_path\\\"],\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trainer import gan_trainer as gan_trainer_module\n",
    "\n",
    "gan_trainer_module = imp.reload(gan_trainer_module)\n",
    "\n",
    "GAN_CONFIG[\"num_train_examples\"] = len(train_dataloader.dataset)\n",
    "gan_trainer = gan_trainer_module.GANTrainerMultipleChoice(\n",
    "    config=GAN_CONFIG,\n",
    "    discriminator=discriminator,\n",
    "    generator=generator,\n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    device=device,\n",
    "    save_path=CONFIG['save_path']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591008,
     "status": "ok",
     "timestamp": 1683654410706,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "jyfUJg0DqlkN",
    "outputId": "55956ec4-f34c-4410-9ef8-4bdd4ebd17b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/vmalperovich/gan-in-nlp/e/GAN2-322\n",
      "======== Epoch 1 / 3 ========\n",
      "\tTrain loss discriminator: 1.976\n",
      "\tTrain loss generator: 0.901\n",
      "Best model saved!\n",
      "\tTest loss discriminator: 1.457\n",
      "\tTest accuracy discriminator: 0.317\n",
      "\tTest f1 discriminator: 0.317\n",
      "======== Epoch 2 / 3 ========\n",
      "\tTrain loss discriminator: 1.140\n",
      "\tTrain loss generator: 0.842\n",
      "\tTest loss discriminator: 1.903\n",
      "\tTest accuracy discriminator: 0.314\n",
      "\tTest f1 discriminator: 0.314\n",
      "======== Epoch 3 / 3 ========\n",
      "\tTrain loss discriminator: 0.816\n",
      "\tTrain loss generator: 0.808\n",
      "Best model saved!\n",
      "\tTest loss discriminator: 1.963\n",
      "\tTest accuracy discriminator: 0.333\n",
      "\tTest f1 discriminator: 0.333\n",
      "CPU times: user 5min 19s, sys: 1.44 s, total: 5min 20s\n",
      "Wall time: 5min 21s\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 112;\n                var nbb_unformatted_code = \"%%time\\nrun = None\\nrun = neptune.init_run(\\n    project=secret[\\\"neptune_project\\\"], api_token=secret[\\\"neptune_token\\\"], tags=tags\\n)\\nrun[\\\"config\\\"] = gan_trainer.config\\n\\n\\nfor epoch_i in range(GAN_CONFIG[\\\"num_train_epochs\\\"]):\\n    print(f\\\"======== Epoch {epoch_i + 1} / {GAN_CONFIG['num_train_epochs']} ========\\\")\\n    train_info = gan_trainer.train_epoch(log_env=run)\\n    result = gan_trainer.validation(log_env=run)\\n# run.stop()\";\n                var nbb_formatted_code = \"%%time\\nrun = None\\nrun = neptune.init_run(\\n    project=secret[\\\"neptune_project\\\"], api_token=secret[\\\"neptune_token\\\"], tags=tags\\n)\\nrun[\\\"config\\\"] = gan_trainer.config\\n\\n\\nfor epoch_i in range(GAN_CONFIG[\\\"num_train_epochs\\\"]):\\n    print(f\\\"======== Epoch {epoch_i + 1} / {GAN_CONFIG['num_train_epochs']} ========\\\")\\n    train_info = gan_trainer.train_epoch(log_env=run)\\n    result = gan_trainer.validation(log_env=run)\\n# run.stop()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "run = None\n",
    "run = neptune.init_run(\n",
    "    project=secret[\"neptune_project\"], api_token=secret[\"neptune_token\"], tags=tags\n",
    ")\n",
    "run[\"config\"] = gan_trainer.config\n",
    "\n",
    "\n",
    "for epoch_i in range(GAN_CONFIG[\"num_train_epochs\"]):\n",
    "    print(f\"======== Epoch {epoch_i + 1} / {GAN_CONFIG['num_train_epochs']} ========\")\n",
    "    train_info = gan_trainer.train_epoch(log_env=run)\n",
    "    result = gan_trainer.validation(log_env=run)\n",
    "# run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111980,
     "status": "ok",
     "timestamp": 1683654522665,
     "user": {
      "displayName": "Вадим Альперович",
      "userId": "02416847696576149422"
     },
     "user_tz": -180
    },
    "id": "FhD2XEovpOLE",
    "outputId": "4f3d3cd6-e75b-4e7d-83ac-72bd4ede4e25"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"# %%time\\n# discriminator.load_state_dict(torch.load(CONFIG[\\\"save_path\\\"]))\\n# predict_info = gan_trainer.predict(\\n#     discriminator, test_dataloader, label_names=CONFIG[\\\"label_names\\\"]\\n# )\\n# run[\\\"test\\\"] = predict_info\\n# run.stop()\\n# predict_info\";\n                var nbb_formatted_code = \"# %%time\\n# discriminator.load_state_dict(torch.load(CONFIG[\\\"save_path\\\"]))\\n# predict_info = gan_trainer.predict(\\n#     discriminator, test_dataloader, label_names=CONFIG[\\\"label_names\\\"]\\n# )\\n# run[\\\"test\\\"] = predict_info\\n# run.stop()\\n# predict_info\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "discriminator.load_state_dict(torch.load(CONFIG[\"save_path\"]))\n",
    "predict_info = gan_trainer.predict(\n",
    "    discriminator, test_dataloader, label_names=CONFIG[\"label_names\"]\n",
    ")\n",
    "run[\"test\"] = predict_info\n",
    "run.stop()\n",
    "predict_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 129;\n                var nbb_unformatted_code = \"from trainer import trainer as trainer_module\\nfrom trainer import gan_trainer as gan_trainer_module\\n\\n\\n# model_name = \\\"bert-base-cased\\\"\\n# model_name = \\\"google/electra-small-discriminator\\\"\\n# model_name = \\\"bert-base-uncased\\\"\\nmodel_name = \\\"google/electra-base-discriminator\\\"\\n# model_name = \\\"distilbert-base-uncased\\\"\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\\n\\ntags = [\\\"FINAL\\\", \\\"updated_qa\\\"]\";\n                var nbb_formatted_code = \"from trainer import trainer as trainer_module\\nfrom trainer import gan_trainer as gan_trainer_module\\n\\n\\n# model_name = \\\"bert-base-cased\\\"\\n# model_name = \\\"google/electra-small-discriminator\\\"\\n# model_name = \\\"bert-base-uncased\\\"\\nmodel_name = \\\"google/electra-base-discriminator\\\"\\n# model_name = \\\"distilbert-base-uncased\\\"\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\\n\\ntags = [\\\"FINAL\\\", \\\"updated_qa\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trainer import trainer as trainer_module\n",
    "from trainer import gan_trainer as gan_trainer_module\n",
    "\n",
    "\n",
    "\n",
    "# model_name = \"bert-base-uncased\"\n",
    "# model_name = \"google/electra-small-discriminator\"\n",
    "model_name = \"google/electra-base-discriminator\"\n",
    "# model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n",
    "\n",
    "tags = [\"FINAL\", \"updated_qa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "800\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 130;\n                var nbb_unformatted_code = \"CONFIG[\\\"encoder_name\\\"] = model_name\\nCONFIG[\\\"noise_range\\\"] = (-2, 2)\\nCONFIG[\\\"noise_range_str\\\"] = str(CONFIG[\\\"noise_range\\\"])\\nCONFIG[\\\"noise_type\\\"] = \\\"uniform\\\"\\nCONFIG[\\\"num_train_epochs\\\"] = 3\\nCONFIG[\\\"gen_multiplier\\\"] = 4\\nprint(CONFIG[\\\"num_labels\\\"])\\n\\nNUM_TRIALS_GAN = 2\\nUNLABELED_SIZE = CONFIG[\\\"num_labels\\\"] * 200\\nprint(UNLABELED_SIZE)\";\n                var nbb_formatted_code = \"CONFIG[\\\"encoder_name\\\"] = model_name\\nCONFIG[\\\"noise_range\\\"] = (-2, 2)\\nCONFIG[\\\"noise_range_str\\\"] = str(CONFIG[\\\"noise_range\\\"])\\nCONFIG[\\\"noise_type\\\"] = \\\"uniform\\\"\\nCONFIG[\\\"num_train_epochs\\\"] = 3\\nCONFIG[\\\"gen_multiplier\\\"] = 4\\nprint(CONFIG[\\\"num_labels\\\"])\\n\\nNUM_TRIALS_GAN = 2\\nUNLABELED_SIZE = CONFIG[\\\"num_labels\\\"] * 200\\nprint(UNLABELED_SIZE)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CONFIG[\"encoder_name\"] = model_name\n",
    "CONFIG[\"noise_range\"] = (-2, 2)\n",
    "CONFIG[\"noise_range_str\"] = str(CONFIG[\"noise_range\"])\n",
    "CONFIG[\"noise_type\"] = \"uniform\"\n",
    "CONFIG[\"num_train_epochs\"] = 3\n",
    "CONFIG[\"gen_multiplier\"] = 4\n",
    "print(CONFIG[\"num_labels\"])\n",
    "\n",
    "NUM_TRIALS_GAN = 2\n",
    "UNLABELED_SIZE = CONFIG[\"num_labels\"] * 200\n",
    "print(UNLABELED_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"# for per_label in tqdm_notebook([5, 10, 20, 50]):\\n#     LABELED_SIZE = CONFIG[\\\"num_labels\\\"] * per_label\\n#     print(f\\\"\\\\n\\\\n\\\\n****************{LABELED_SIZE}***********\\\\n\\\\n\\\\n\\\")\\n\\n#     CONFIG[\\\"per_label_samples\\\"] = per_label\\n#     try:\\n#         del discriminator\\n#     except:\\n#         pass\\n#     torch.cuda.empty_cache()\\n#     gc.collect()\\n#     FULL_SIZE = LABELED_SIZE + UNLABELED_SIZE\\n#     multiplier = int(np.log2(FULL_SIZE / LABELED_SIZE)) - 1\\n#     multiplier = max(1, multiplier)\\n#     print(\\\"Multiplier:\\\", multiplier)\\n\\n#     tokenized_dataset = prepare_experiment_datasets(\\n#         LABELED_SIZE, UNLABELED_SIZE, FULL_SIZE, multiplier\\n#     )\\n\\n#     train_only_labeled_dataloader = DataLoader(\\n#         tokenized_dataset[\\\"train_only_labeled\\\"],\\n#         batch_size=CONFIG[\\\"batch_size\\\"],\\n#         sampler=RandomSampler(tokenized_dataset[\\\"train_only_labeled\\\"]),\\n#         collate_fn=data_collator,\\n#         pin_memory=True,\\n#     )\\n\\n#     train_dataloader = DataLoader(\\n#         tokenized_dataset[\\\"train\\\"],\\n#         batch_size=CONFIG[\\\"batch_size\\\"],\\n#         sampler=RandomSampler(tokenized_dataset[\\\"train\\\"]),\\n#         collate_fn=data_collator,\\n#         pin_memory=True,\\n#     )\\n\\n#     valid_dataloader = DataLoader(\\n#         tokenized_dataset[\\\"validation\\\"],\\n#         batch_size=CONFIG[\\\"batch_size\\\"],\\n#         sampler=SequentialSampler(tokenized_dataset[\\\"validation\\\"]),\\n#         collate_fn=data_collator,\\n#         pin_memory=True,\\n#     )\\n\\n#     test_dataloader = DataLoader(\\n#         tokenized_dataset[\\\"test\\\"],\\n#         batch_size=16,\\n#         sampler=SequentialSampler(tokenized_dataset[\\\"test\\\"]),\\n#         collate_fn=data_collator,\\n#         pin_memory=True,\\n#     )\\n#     for _ in range(1):\\n#         # NO GAN\\n#         print(\\\"NO GAN...\\\")\\n#         try:\\n#             del discriminator\\n#         except:\\n#             pass\\n#         torch.cuda.empty_cache()\\n#         gc.collect()\\n#         BASE_CONFIG = copy(CONFIG)\\n#         BASE_CONFIG[\\\"num_train_examples\\\"] = len(train_only_labeled_dataloader.dataset)\\n#         BASE_CONFIG[\\\"GAN\\\"] = False\\n#         BASE_CONFIG[\\\"gan_training\\\"] = False\\n#         BASE_CONFIG[\\\"LABELED_SIZE\\\"] = LABELED_SIZE\\n#         discriminator = model.DiscriminatorForMultipleChoice(**BASE_CONFIG)\\n#         print(discriminator.encoder_name)\\n#         trainer = trainer_module.TrainerSequenceClassification(\\n#             config=BASE_CONFIG,\\n#             discriminator=discriminator,\\n#             train_dataloader=train_only_labeled_dataloader,\\n#             valid_dataloader=valid_dataloader,\\n#             device=device,\\n#         )\\n#         run = neptune.init_run(\\n#             project=secret[\\\"neptune_project\\\"],\\n#             api_token=secret[\\\"neptune_token\\\"],\\n#             tags=tags,\\n#         )\\n#         run[\\\"config\\\"] = trainer.config\\n\\n#         for epoch_i in range(BASE_CONFIG[\\\"num_train_epochs\\\"]):\\n#             print(f\\\"== Epoch {epoch_i + 1} / {BASE_CONFIG['num_train_epochs']} ==\\\")\\n#             train_info = trainer.train_epoch(log_env=run)\\n#             valid_metrics = trainer.validation(log_env=run)\\n#         predict_info = trainer.predict(\\n#             discriminator, test_dataloader, label_names=CONFIG[\\\"label_names\\\"]\\n#         )\\n#         run[\\\"test\\\"] = predict_info\\n#         run.stop()\\n\\n#     for _ in range(NUM_TRIALS_GAN):\\n#         # GAN\\n#         print(\\\"GAN...\\\")\\n#         del discriminator\\n#         gc.collect()\\n#         torch.cuda.empty_cache()\\n#         GAN_CONFIG = copy(CONFIG)\\n#         GAN_CONFIG[\\\"GAN\\\"] = True\\n#         GAN_CONFIG[\\\"gan_training\\\"] = True\\n#         GAN_CONFIG[\\\"GAN_TYPE\\\"] = \\\"dummy\\\"\\n#         GAN_CONFIG[\\\"LABELED_SIZE\\\"] = LABELED_SIZE\\n#         GAN_CONFIG[\\\"UNLABELED_SIZE\\\"] = UNLABELED_SIZE\\n#         GAN_CONFIG[\\\"FULL_SIZE\\\"] = FULL_SIZE\\n#         discriminator = model.DiscriminatorForMultipleChoice(**GAN_CONFIG)\\n#         generator = model.SimpleSequenceGenerator(\\n#             input_size=CONFIG[\\\"noise_size\\\"],\\n#             output_size=discriminator.encoder.config.hidden_size,\\n#         )\\n\\n#         GAN_CONFIG[\\\"num_train_examples\\\"] = len(train_dataloader.dataset)\\n#         gan_trainer = gan_trainer_module.GANTrainerMultipleChoice(\\n#             config=GAN_CONFIG,\\n#             discriminator=discriminator,\\n#             generator=generator,\\n#             train_dataloader=train_dataloader,\\n#             valid_dataloader=valid_dataloader,\\n#             device=device,\\n#             save_path=CONFIG[\\\"save_path\\\"],\\n#         )\\n#         run = neptune.init_run(\\n#             project=secret[\\\"neptune_project\\\"],\\n#             api_token=secret[\\\"neptune_token\\\"],\\n#             tags=tags,\\n#         )\\n#         run[\\\"config\\\"] = gan_trainer.config\\n\\n#         for epoch_i in range(GAN_CONFIG[\\\"num_train_epochs\\\"]):\\n#             print(f\\\"== Epoch {epoch_i + 1} / {GAN_CONFIG['num_train_epochs']} ==\\\")\\n#             train_info = gan_trainer.train_epoch(log_env=run)\\n#             result = gan_trainer.validation(log_env=run)\\n#         discriminator.load_state_dict(torch.load(CONFIG[\\\"save_path\\\"]))\\n#         predict_info = gan_trainer.predict(\\n#             discriminator, test_dataloader, label_names=CONFIG[\\\"label_names\\\"]\\n#         )\\n#         run[\\\"test\\\"] = predict_info\\n#         run.stop()\";\n                var nbb_formatted_code = \"# for per_label in tqdm_notebook([5, 10, 20, 50]):\\n#     LABELED_SIZE = CONFIG[\\\"num_labels\\\"] * per_label\\n#     print(f\\\"\\\\n\\\\n\\\\n****************{LABELED_SIZE}***********\\\\n\\\\n\\\\n\\\")\\n\\n#     CONFIG[\\\"per_label_samples\\\"] = per_label\\n#     try:\\n#         del discriminator\\n#     except:\\n#         pass\\n#     torch.cuda.empty_cache()\\n#     gc.collect()\\n#     FULL_SIZE = LABELED_SIZE + UNLABELED_SIZE\\n#     multiplier = int(np.log2(FULL_SIZE / LABELED_SIZE)) - 1\\n#     multiplier = max(1, multiplier)\\n#     print(\\\"Multiplier:\\\", multiplier)\\n\\n#     tokenized_dataset = prepare_experiment_datasets(\\n#         LABELED_SIZE, UNLABELED_SIZE, FULL_SIZE, multiplier\\n#     )\\n\\n#     train_only_labeled_dataloader = DataLoader(\\n#         tokenized_dataset[\\\"train_only_labeled\\\"],\\n#         batch_size=CONFIG[\\\"batch_size\\\"],\\n#         sampler=RandomSampler(tokenized_dataset[\\\"train_only_labeled\\\"]),\\n#         collate_fn=data_collator,\\n#         pin_memory=True,\\n#     )\\n\\n#     train_dataloader = DataLoader(\\n#         tokenized_dataset[\\\"train\\\"],\\n#         batch_size=CONFIG[\\\"batch_size\\\"],\\n#         sampler=RandomSampler(tokenized_dataset[\\\"train\\\"]),\\n#         collate_fn=data_collator,\\n#         pin_memory=True,\\n#     )\\n\\n#     valid_dataloader = DataLoader(\\n#         tokenized_dataset[\\\"validation\\\"],\\n#         batch_size=CONFIG[\\\"batch_size\\\"],\\n#         sampler=SequentialSampler(tokenized_dataset[\\\"validation\\\"]),\\n#         collate_fn=data_collator,\\n#         pin_memory=True,\\n#     )\\n\\n#     test_dataloader = DataLoader(\\n#         tokenized_dataset[\\\"test\\\"],\\n#         batch_size=16,\\n#         sampler=SequentialSampler(tokenized_dataset[\\\"test\\\"]),\\n#         collate_fn=data_collator,\\n#         pin_memory=True,\\n#     )\\n#     for _ in range(1):\\n#         # NO GAN\\n#         print(\\\"NO GAN...\\\")\\n#         try:\\n#             del discriminator\\n#         except:\\n#             pass\\n#         torch.cuda.empty_cache()\\n#         gc.collect()\\n#         BASE_CONFIG = copy(CONFIG)\\n#         BASE_CONFIG[\\\"num_train_examples\\\"] = len(train_only_labeled_dataloader.dataset)\\n#         BASE_CONFIG[\\\"GAN\\\"] = False\\n#         BASE_CONFIG[\\\"gan_training\\\"] = False\\n#         BASE_CONFIG[\\\"LABELED_SIZE\\\"] = LABELED_SIZE\\n#         discriminator = model.DiscriminatorForMultipleChoice(**BASE_CONFIG)\\n#         print(discriminator.encoder_name)\\n#         trainer = trainer_module.TrainerSequenceClassification(\\n#             config=BASE_CONFIG,\\n#             discriminator=discriminator,\\n#             train_dataloader=train_only_labeled_dataloader,\\n#             valid_dataloader=valid_dataloader,\\n#             device=device,\\n#         )\\n#         run = neptune.init_run(\\n#             project=secret[\\\"neptune_project\\\"],\\n#             api_token=secret[\\\"neptune_token\\\"],\\n#             tags=tags,\\n#         )\\n#         run[\\\"config\\\"] = trainer.config\\n\\n#         for epoch_i in range(BASE_CONFIG[\\\"num_train_epochs\\\"]):\\n#             print(f\\\"== Epoch {epoch_i + 1} / {BASE_CONFIG['num_train_epochs']} ==\\\")\\n#             train_info = trainer.train_epoch(log_env=run)\\n#             valid_metrics = trainer.validation(log_env=run)\\n#         predict_info = trainer.predict(\\n#             discriminator, test_dataloader, label_names=CONFIG[\\\"label_names\\\"]\\n#         )\\n#         run[\\\"test\\\"] = predict_info\\n#         run.stop()\\n\\n#     for _ in range(NUM_TRIALS_GAN):\\n#         # GAN\\n#         print(\\\"GAN...\\\")\\n#         del discriminator\\n#         gc.collect()\\n#         torch.cuda.empty_cache()\\n#         GAN_CONFIG = copy(CONFIG)\\n#         GAN_CONFIG[\\\"GAN\\\"] = True\\n#         GAN_CONFIG[\\\"gan_training\\\"] = True\\n#         GAN_CONFIG[\\\"GAN_TYPE\\\"] = \\\"dummy\\\"\\n#         GAN_CONFIG[\\\"LABELED_SIZE\\\"] = LABELED_SIZE\\n#         GAN_CONFIG[\\\"UNLABELED_SIZE\\\"] = UNLABELED_SIZE\\n#         GAN_CONFIG[\\\"FULL_SIZE\\\"] = FULL_SIZE\\n#         discriminator = model.DiscriminatorForMultipleChoice(**GAN_CONFIG)\\n#         generator = model.SimpleSequenceGenerator(\\n#             input_size=CONFIG[\\\"noise_size\\\"],\\n#             output_size=discriminator.encoder.config.hidden_size,\\n#         )\\n\\n#         GAN_CONFIG[\\\"num_train_examples\\\"] = len(train_dataloader.dataset)\\n#         gan_trainer = gan_trainer_module.GANTrainerMultipleChoice(\\n#             config=GAN_CONFIG,\\n#             discriminator=discriminator,\\n#             generator=generator,\\n#             train_dataloader=train_dataloader,\\n#             valid_dataloader=valid_dataloader,\\n#             device=device,\\n#             save_path=CONFIG[\\\"save_path\\\"],\\n#         )\\n#         run = neptune.init_run(\\n#             project=secret[\\\"neptune_project\\\"],\\n#             api_token=secret[\\\"neptune_token\\\"],\\n#             tags=tags,\\n#         )\\n#         run[\\\"config\\\"] = gan_trainer.config\\n\\n#         for epoch_i in range(GAN_CONFIG[\\\"num_train_epochs\\\"]):\\n#             print(f\\\"== Epoch {epoch_i + 1} / {GAN_CONFIG['num_train_epochs']} ==\\\")\\n#             train_info = gan_trainer.train_epoch(log_env=run)\\n#             result = gan_trainer.validation(log_env=run)\\n#         discriminator.load_state_dict(torch.load(CONFIG[\\\"save_path\\\"]))\\n#         predict_info = gan_trainer.predict(\\n#             discriminator, test_dataloader, label_names=CONFIG[\\\"label_names\\\"]\\n#         )\\n#         run[\\\"test\\\"] = predict_info\\n#         run.stop()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for per_label in tqdm_notebook([5, 10, 20, 50]):\n",
    "    LABELED_SIZE = CONFIG[\"num_labels\"] * per_label\n",
    "    print(f\"\\n\\n\\n****************{LABELED_SIZE}***********\\n\\n\\n\")\n",
    "\n",
    "    CONFIG[\"per_label_samples\"] = per_label\n",
    "    try:\n",
    "        del discriminator\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    FULL_SIZE = LABELED_SIZE + UNLABELED_SIZE\n",
    "    multiplier = int(np.log2(FULL_SIZE / LABELED_SIZE)) - 1\n",
    "    multiplier = max(1, multiplier)\n",
    "    print(\"Multiplier:\", multiplier)\n",
    "\n",
    "    tokenized_dataset = prepare_experiment_datasets(\n",
    "        LABELED_SIZE, UNLABELED_SIZE, FULL_SIZE, multiplier\n",
    "    )\n",
    "\n",
    "    train_only_labeled_dataloader = DataLoader(\n",
    "        tokenized_dataset[\"train_only_labeled\"],\n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        sampler=RandomSampler(tokenized_dataset[\"train_only_labeled\"]),\n",
    "        collate_fn=data_collator,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        tokenized_dataset[\"train\"],\n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        sampler=RandomSampler(tokenized_dataset[\"train\"]),\n",
    "        collate_fn=data_collator,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    valid_dataloader = DataLoader(\n",
    "        tokenized_dataset[\"validation\"],\n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        sampler=SequentialSampler(tokenized_dataset[\"validation\"]),\n",
    "        collate_fn=data_collator,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        tokenized_dataset[\"test\"],\n",
    "        batch_size=16,\n",
    "        sampler=SequentialSampler(tokenized_dataset[\"test\"]),\n",
    "        collate_fn=data_collator,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    for _ in range(1):\n",
    "        # NO GAN\n",
    "        print(\"NO GAN...\")\n",
    "        try:\n",
    "            del discriminator\n",
    "        except:\n",
    "            pass\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        BASE_CONFIG = copy(CONFIG)\n",
    "        BASE_CONFIG[\"num_train_examples\"] = len(train_only_labeled_dataloader.dataset)\n",
    "        BASE_CONFIG[\"GAN\"] = False\n",
    "        BASE_CONFIG[\"gan_training\"] = False\n",
    "        BASE_CONFIG[\"LABELED_SIZE\"] = LABELED_SIZE\n",
    "        discriminator = model.DiscriminatorForMultipleChoice(**BASE_CONFIG)\n",
    "        print(discriminator.encoder_name)\n",
    "        trainer = trainer_module.TrainerSequenceClassification(\n",
    "            config=BASE_CONFIG,\n",
    "            discriminator=discriminator,\n",
    "            train_dataloader=train_only_labeled_dataloader,\n",
    "            valid_dataloader=valid_dataloader,\n",
    "            device=device,\n",
    "        )\n",
    "        run = neptune.init_run(\n",
    "            project=secret[\"neptune_project\"],\n",
    "            api_token=secret[\"neptune_token\"],\n",
    "            tags=tags,\n",
    "        )\n",
    "        run[\"config\"] = trainer.config\n",
    "\n",
    "        for epoch_i in range(BASE_CONFIG[\"num_train_epochs\"]):\n",
    "            print(f\"== Epoch {epoch_i + 1} / {BASE_CONFIG['num_train_epochs']} ==\")\n",
    "            train_info = trainer.train_epoch(log_env=run)\n",
    "            valid_metrics = trainer.validation(log_env=run)\n",
    "        predict_info = trainer.predict(\n",
    "            discriminator, test_dataloader, label_names=CONFIG[\"label_names\"]\n",
    "        )\n",
    "        run[\"test\"] = predict_info\n",
    "        run.stop()\n",
    "\n",
    "    for _ in range(NUM_TRIALS_GAN):\n",
    "        # GAN\n",
    "        print(\"GAN...\")\n",
    "        del discriminator\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        GAN_CONFIG = copy(CONFIG)\n",
    "        GAN_CONFIG[\"GAN\"] = True\n",
    "        GAN_CONFIG[\"gan_training\"] = True\n",
    "        GAN_CONFIG[\"GAN_TYPE\"] = \"dummy\"\n",
    "        GAN_CONFIG[\"LABELED_SIZE\"] = LABELED_SIZE\n",
    "        GAN_CONFIG[\"UNLABELED_SIZE\"] = UNLABELED_SIZE\n",
    "        GAN_CONFIG[\"FULL_SIZE\"] = FULL_SIZE\n",
    "        discriminator = model.DiscriminatorForMultipleChoice(**GAN_CONFIG)\n",
    "        generator = model.SimpleSequenceGenerator(\n",
    "            input_size=CONFIG[\"noise_size\"],\n",
    "            output_size=discriminator.encoder.config.hidden_size,\n",
    "        )\n",
    "\n",
    "        GAN_CONFIG[\"num_train_examples\"] = len(train_dataloader.dataset)\n",
    "        gan_trainer = gan_trainer_module.GANTrainerMultipleChoice(\n",
    "            config=GAN_CONFIG,\n",
    "            discriminator=discriminator,\n",
    "            generator=generator,\n",
    "            train_dataloader=train_dataloader,\n",
    "            valid_dataloader=valid_dataloader,\n",
    "            device=device,\n",
    "            save_path=CONFIG[\"save_path\"],\n",
    "        )\n",
    "        run = neptune.init_run(\n",
    "            project=secret[\"neptune_project\"],\n",
    "            api_token=secret[\"neptune_token\"],\n",
    "            tags=tags,\n",
    "        )\n",
    "        run[\"config\"] = gan_trainer.config\n",
    "\n",
    "        for epoch_i in range(GAN_CONFIG[\"num_train_epochs\"]):\n",
    "            print(f\"== Epoch {epoch_i + 1} / {GAN_CONFIG['num_train_epochs']} ==\")\n",
    "            train_info = gan_trainer.train_epoch(log_env=run)\n",
    "            result = gan_trainer.validation(log_env=run)\n",
    "        discriminator.load_state_dict(torch.load(CONFIG[\"save_path\"]))\n",
    "        predict_info = gan_trainer.predict(\n",
    "            discriminator, test_dataloader, label_names=CONFIG[\"label_names\"]\n",
    "        )\n",
    "        run[\"test\"] = predict_info\n",
    "        run.stop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SZgyRUTEhuV3"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "25442d3b2dde4bdfa448cf3529a248c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e510ae3f8934b9fbf5bf0f92fae7189",
       "IPY_MODEL_d9bbc48c93644c8385e38d11eaf5f094",
       "IPY_MODEL_bbf6876771574e1db8f3c4c2c53c723a"
      ],
      "layout": "IPY_MODEL_93adbfa4262046a2a71ee27457ea82ef"
     }
    },
    "28603900eb814caf9f7cd38bb02d2fbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2934b3ded05946ad9d9a769fa9c18e40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40f7c02c456b4cf48e48ef899d6298e2",
       "IPY_MODEL_f10c9bb2ddf0416ab6fdb62a73282d8d",
       "IPY_MODEL_b52e189d0fbf4fb599f785db61264f60"
      ],
      "layout": "IPY_MODEL_aa4ecbd29ebb47febd410b89b9691cd0"
     }
    },
    "2c9c9824ab174f5aa54b5316582e971c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_766279c212934acba30470a4457c1c86",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f88c1bdc9e444778cca9b16abb23057",
      "value": 3
     }
    },
    "2e510ae3f8934b9fbf5bf0f92fae7189": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_445c0cae8cb64de4bc10cc929da18498",
      "placeholder": "​",
      "style": "IPY_MODEL_f56c633fe7514173bc905261e84dfe8c",
      "value": "Map: 100%"
     }
    },
    "3f88c1bdc9e444778cca9b16abb23057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "40f7c02c456b4cf48e48ef899d6298e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_795d3f27fd254299bae07e9c10b75cdf",
      "placeholder": "​",
      "style": "IPY_MODEL_787d231e62fa498bb11d2d4a603d7fd3",
      "value": "Map: 100%"
     }
    },
    "445c0cae8cb64de4bc10cc929da18498": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ca28c30c94844109458a57a7e6c53a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d6e56e8cba246059d2fa50bc50aab86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50f8cd6b219847d8b24f6f60ced67eb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76a885b741a94ce993130df9dc898222",
       "IPY_MODEL_2c9c9824ab174f5aa54b5316582e971c",
       "IPY_MODEL_5134486956da4c378135dcf2745a5667"
      ],
      "layout": "IPY_MODEL_e115c69d2819440ea36c604102a5f33a"
     }
    },
    "5134486956da4c378135dcf2745a5667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d6e56e8cba246059d2fa50bc50aab86",
      "placeholder": "​",
      "style": "IPY_MODEL_a1f601f76549446490a900beace4b9e0",
      "value": " 3/3 [00:00&lt;00:00, 151.78it/s]"
     }
    },
    "51b23e6fa6964561930bb878b650661f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "539109a29e234f48a87f81a8394804ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59a641177b8a49b8b757d2faf50dc502": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "766279c212934acba30470a4457c1c86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76a885b741a94ce993130df9dc898222": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51b23e6fa6964561930bb878b650661f",
      "placeholder": "​",
      "style": "IPY_MODEL_4ca28c30c94844109458a57a7e6c53a1",
      "value": "100%"
     }
    },
    "787d231e62fa498bb11d2d4a603d7fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "795d3f27fd254299bae07e9c10b75cdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85893c61fee946c586488e2e04dc6fbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93adbfa4262046a2a71ee27457ea82ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "94c0292f9cb04f5698e678d1d73c84e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1f601f76549446490a900beace4b9e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa4ecbd29ebb47febd410b89b9691cd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "ab41570799b249cea878f4dba904f350": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b52e189d0fbf4fb599f785db61264f60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28603900eb814caf9f7cd38bb02d2fbb",
      "placeholder": "​",
      "style": "IPY_MODEL_94c0292f9cb04f5698e678d1d73c84e9",
      "value": " 25262/25262 [00:21&lt;00:00, 1061.32 examples/s]"
     }
    },
    "bbf6876771574e1db8f3c4c2c53c723a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_539109a29e234f48a87f81a8394804ae",
      "placeholder": "​",
      "style": "IPY_MODEL_c97c3b4ea0cf4f94ad19a6f258a7808c",
      "value": " 2985/2985 [00:02&lt;00:00, 1226.70 examples/s]"
     }
    },
    "c97c3b4ea0cf4f94ad19a6f258a7808c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0aed566e6c04491b0d98bbf5fc70e41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9bbc48c93644c8385e38d11eaf5f094": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab41570799b249cea878f4dba904f350",
      "max": 2985,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59a641177b8a49b8b757d2faf50dc502",
      "value": 2985
     }
    },
    "e115c69d2819440ea36c604102a5f33a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f10c9bb2ddf0416ab6fdb62a73282d8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85893c61fee946c586488e2e04dc6fbf",
      "max": 25262,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0aed566e6c04491b0d98bbf5fc70e41",
      "value": 25262
     }
    },
    "f56c633fe7514173bc905261e84dfe8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
